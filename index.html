<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>XSRL: Cross-Lingual Semantic Role Labeling with High-Quality Translated Training Corpus</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.icon">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Cross-Lingual Semantic Role Labeling with High-Quality Translated Training Corpus</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://haofei.vip/">Hao Fei</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://zhangmeishan.github.io/">Meishan Zhang</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="#">Donghong Ji</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Wuhan University,</span>&nbsp;&nbsp;
            <span class="author-block"><sup>2</sup>Harbin Institute of Technology (Shenzhen),</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://aclanthology.org/2020.acl-main.627/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2004.06295"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/scofield7419/XSRL-ACL"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

<!--              &lt;!&ndash; Poster Link. &ndash;&gt;-->
<!--              <span class="link-block">-->
<!--              <a href="./static/media/conference_poster_portrait_ACL23_ISA.pdf" class="external-link button is-normal is-rounded is-dark">-->
<!--                <span class="icon">-->
<!--                    <svg class="svg-inline&#45;&#45;fa fa-chalkboard fa-w-20" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="chalkboard" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512" data-fa-i2svg=""><path fill="currentColor" d="M96 64h448v352h64V40c0-22.06-17.94-40-40-40H72C49.94 0 32 17.94 32 40v376h64V64zm528 384H480v-64H288v64H16c-8.84 0-16 7.16-16 16v32c0 8.84 7.16 16 16 16h608c8.84 0 16-7.16 16-16v-32c0-8.84-7.16-16-16-16z"></path></svg>&lt;!&ndash; <i class="fas fa-chalkboard"></i> Font Awesome fontawesome.com &ndash;&gt;-->
<!--                </span>-->
<!--                <span>Poster</span>-->
<!--              </a>-->
<!--            </span>-->

<!--               Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/scofield7419/XSRL-ACL/tree/master/UP_English"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-file"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>

              <!-- Video Link. -->
              <span class="link-block">
                <a href="./static/media/remake-full.mp4"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!--<section class="hero teaser">-->
<!--  <div class="container is-max-desktop">-->
<!--    <div class="hero-body">-->
<!--      <video id="teaser" autoplay muted loop playsinline height="100%">-->
<!--        <source src="./static/videos/teaser.mp4"-->
<!--                type="video/mp4">-->
<!--      </video>-->
<!--      <h2 class="subtitle has-text-centered">-->
<!--        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into-->
<!--        free-viewpoint-->
<!--        portraits.-->
<!--      </h2>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->


<!--<section class="hero is-light is-small">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      <div id="results-carousel" class="carousel results-carousel">-->
<!--        <div class="item item-steve">-->
<!--          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/steve.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-chair-tp">-->
<!--          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/chair-tp.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-shiba">-->
<!--          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/shiba.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-fullbody">-->
<!--          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/fullbody.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-blueshirt">-->
<!--          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/blueshirt.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-mask">-->
<!--          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/mask.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-coffee">-->
<!--          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/coffee.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-toby">-->
<!--          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/toby2.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Many efforts of research are devoted to semantic role labeling (SRL) which is crucial for natural language understanding. Supervised approaches have achieved impressing performances when large-scale corpora are available for resource-rich languages such as English. While for the low-resource languages with no annotated SRL dataset, it is still challenging to obtain competitive performances. Cross-lingual SRL is one promising way to address the problem, which has achieved great advances with the help of model transferring and annotation projection. In this paper, we propose a novel alternative based on corpus translation, constructing high-quality training datasets for the target languages from the source gold-standard SRL annotations. Experimental results on Universal Proposition Bank show that the translation-based method is highly effective, and the automatic pseudo datasets can improve the target-language SRL performances significantly.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Presentation</h2>
        <div class="publication-video" style="padding-bottom: 500px">
          <video   controls playsinline height="100%" width="100%" style="padding: -20px">
              <source src="./static/media/remake-full.mp4" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Paper intro. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Motivation</h2>
          <p style="text-align:left">
            <b>Model transferring</b> and <b>annotation projection</b> are two mainstream categories for the cross-lingual transfer learning.
            The former builds cross-lingual models on language-independent features such as cross-lingual word representations and universal POS tags which can be transferred into target languages directly.
            The latter bases on a large-scale parallel corpus between the source and target languages where the source-side sentences are annotated with SRL tags automatically by a source SRL labeler,
            and then the source annotations are projected onto the target-side sentences in accordance of word alignments.
          </p><br>

        <p style="text-align:left">The annotation projection can be combined with model transferring naturally, where the projected SRL tags in annotation projection could contain much noise because of the source-side automatic annotations. A
        straightforward solution is the translation-based approach, which has been demonstrated effective for cross-lingual dependency parsing.
          The key idea is to translate the gold-standard source training data into target language side by translation directly, avoiding the problem of the low-quality source annotations.
        </p><br>

        <p style="text-align:left">In this project, we study the translation-based method for cross-lingual SRL.
          Sentences of the source language training corpus are translated into the target language, and then the source SRL annotations are projected into the target side, resulting in a set of
          high-quality target language SRL corpus, which is used to train the target SRL model.
          Further, we merge the gold-standard source corpus and the translated target together, which can be regarded as a combination of the translation-based method and the model transferring.
        </p><br>
        <div class="publication-video">
          <img width="56%" src="./static/images/intro.png">
        </div>
      </div>
    </div>
    <!--/ Paper intro. -->
  </div>
</section>



<section class="section" style="margin-top: -200px">
  <div class="container is-max-desktop">
    <!-- Paper intro. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">SRL Translation</h2>

          <div class="column is-four-fifths">
    <!--        <h2 class="title is-3"></h2>-->
            <div class="publication-image" style="text-align:left">
              <p style="text-align:justify">
                <b>Step 1. Translating</b>: produce target translations for the sentences of the source SRL data.
              </p>
            </div>
          </div>

          <div class="column is-four-fifths" >
    <!--        <h2 class="title is-3"></h2>-->
            <div class="publication-image" style="text-align:left">
              <p style="text-align:justify">
                <b>Step 2. Projecting</b>: incrementally project the corresponding predicates or arguments of a source sentence to its target.
              </p>  <br>
            </div>
          </div>

          <br>
        <div class="publication-image" style="margin-top: -30px">
          <img width="90%" src="./static/images/projection.png">
        </div>
      </div>
    </div>
    <!--/ Paper intro. -->
  </div>
</section>



<section class="section" style="margin-top: -10px">
  <div class="container is-max-desktop">
    <!-- Paper method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">SRL Model</h2>
        <p style="text-align:left">
            <b>Model architecture:</b>
          </p>
        <div class="publication-image">
          <img width="60%" src="./static/images/model.png">
        </div>
        <br>

<!--        <div class="columns is-centered has-text-centered">-->
          <div class="column is-four-fifths">
    <!--        <h2 class="title is-3"></h2>-->
            <div class="publication-image" style="text-align:justify">
              <b>PGN-BiLSTM:</b>  For a better exploration of the blended corpus, we adopt a parameter generation
                network (PGN) to enhance the BiLSTM module, which can capture the language differences effectively<br>
              <center><img  width="60%" src="./static/images/PGN.png"></center>
            </div>
          </div>
<!--        </div>-->


      </div>
    </div>
    <!--/ Paper method. -->
  </div>
</section>







<section class="section" style="margin-top: 0px">
  <div class="container is-max-desktop">
    <!-- Paper Experiment. -->
    <div class="columns is-centered has-text-centered">

      <div class="column is-four-fifths">
        <h2 class="title is-3">Experiment</h2>
          <p style="text-align:left">
            <b>Cross-Lingual Transfer from English to other languages.</b>
          </p><br>
        <div class="publication-image">
          <center><img width="60%" src="./static/images/res1.png"></center>
        </div>
        <br>

      <div class="column is-four-fifths" style="width: 100%" >
          <p style="text-align:left">
            <b>Multi-Source Transfer.</b>
          </p><br>
        <div class="publication-image">
          <center><img width="60%" src="./static/images/res2.png"></center>
        </div>
        </div>


      <div class="column is-four-fifths" style="width: 100%" >
          <p style="text-align:left">
            <b>Bilingual Transfer.</b>
          </p><br>
        <div class="publication-image">
          <center><img width="60%" src="./static/images/res3.png"></center>
        </div>
        <div class="publication-image">
          <center><img width="60%" src="./static/images/res4.png"></center>
        </div>
        </div>



      <div class="column is-four-fifths" style="width: 100%" >
          <p style="text-align:left">
            <b>Performances by the SRL roles.</b>
          </p><br>
        <div class="publication-image">
          <center><img width="60%" src="./static/images/res5.png"></center>
        </div>

        </div>



      <div class="column is-four-fifths" style="width: 100%" >
          <p style="text-align:left">
            <b>Performances by the distances to the predicate.</b>
          </p><br>
        <div class="publication-image">
          <center><img width="60%" src="./static/images/res6.png"></center>
        </div>

        </div>


      </div>
      </div>
    <!--/ Paper method. -->
  </div>
</section>








<section class="section">
  <div class="container is-max-desktop">
    <!-- Paper poster. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Paper</h2>
        <div class="publication-image">
          <object data="https://aclanthology.org/2020.acl-main.627.pdf" type="application/pdf" width="100%" height="1110px"></object>
        </div>
      </div>
    </div>
    <!--/ Paper poster. -->
  </div>
</section>






<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{FeiAcl23THOR,
  author    = {Hao Fei, Bobo Li, Qian Liu, Lidong Bing, Fei Li, Tat-Seng Chua},
  title     = {Reasoning Implicit Sentiment with Chain-of-Thought Prompting},
  journal   = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
  year      = {2023},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
<!--    <div class="content has-text-centered">-->
<!--      <a class="icon-link"-->
<!--         href="./static/videos/nerfies_paper.pdf">-->
<!--        <i class="fas fa-file-pdf"></i>-->
<!--      </a>-->
<!--      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>-->
<!--        <i class="fab fa-github"></i>-->
<!--      </a>-->
<!--    </div>-->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            The website template credit to <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>,
            licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 License</a>.
          </p>
<!--          <p>-->
<!--            This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,-->
<!--            we just ask that you link back to this page in the footer.-->
<!--            Please remember to remove the analytics code included in the header of the website which-->
<!--            you do not want on your website.-->
<!--          </p>-->
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
